{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Mnist \n",
    "Starter Pack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Some Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "46ade2a1807aadd90e577c496d77d3df507dad88"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a87c9de979fb54874e3a047d40cc024a8b0f5e98",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0b3d551a62defaadd37e681511ebc5fc70ac944d"
   },
   "outputs": [],
   "source": [
    "y = train_df['label'].values # extract the numpy array\n",
    "X = train_df.drop(['label'],1).values # extract the numpy array\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_test = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "96f0d5dbc90457eb091fb2e6ed68ce7c7bf6da0b"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Tensor Dataset to apply the transform function\n",
    "class CustomTensorDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms like default MNIST datasets from torchvision.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, target=None, transform=None, target_transform=None):\n",
    "        #super(CustomTensorDataset, self).__init__(data=data, target=target, transform=transform, \n",
    "        #                                          target_transform=target_transform)\n",
    "        self.data = data.reshape((-1, 28, 28)).astype(np.float32)/255\n",
    "        print(self.data.shape)\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        # x = Image.fromarray(x, mode='L')\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.target is not None:\n",
    "            y = self.target[index]\n",
    "        else: \n",
    "            y = 0\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35700, 28, 28)\n",
      "(6300, 28, 28)\n",
      "(28000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# The tensors are not normaized. Create the datasets and dataloaders\n",
    "train = CustomTensorDataset(data=X_train,target=y_train,\n",
    "                                       transform=torchvision.transforms.Compose([\n",
    "                                       torchvision.transforms.ToTensor(),\n",
    "                                       torchvision.transforms.Normalize(\n",
    "                                         (0.1311,), (0.3086,))\n",
    "                                     ]))\n",
    "\n",
    "\n",
    "val = CustomTensorDataset(data=X_val,target=y_val,\n",
    "                                      transform=torchvision.transforms.Compose([\n",
    "                                      torchvision.transforms.ToTensor(),\n",
    "                                      torchvision.transforms.Normalize(\n",
    "                                         (0.1311,), (0.3086,))\n",
    "                                     ]))\n",
    "\n",
    "test = CustomTensorDataset(data=X_test,target=None,\n",
    "                                      transform=torchvision.transforms.Compose([\n",
    "                                      torchvision.transforms.ToTensor(),\n",
    "                                      torchvision.transforms.Normalize(\n",
    "                                         (0.1311,), (0.3086,))\n",
    "                                     ]))\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# looking at the train loader\n",
    "dataiter = iter(train_loader) # creating a iterator\n",
    "images, labels = dataiter.next() # creating images for image and lables for image number (0 to 9) \n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdf482c33d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(np.squeeze(images[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "3624b779d746e6b5710711c7b1798363ecabafbb"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    # https://stackoverflow.com/a/40295999/8853476\n",
    "    def __init__(self):\n",
    "        super(CNN , self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, padding=0, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=0, stride=1)\n",
    "        self.conv2_drop = nn.Dropout2d(0.1)\n",
    "        self.fc1 = nn.Linear(in_features=2048, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=10)\n",
    "        # self.bnm = nn.BatchNorm2d(64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # conv --> norm --> activation --> dropout --> pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = self.conv2_drop(F.relu(self.conv2(x))) \n",
    "        x = F.max_pool2d(x, 2)  \n",
    "        x = x.reshape(-1, 2048)\n",
    "        x = F.dropout(F.relu(self.fc1(x)), training=self.training, p=0.2)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2 , self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=0, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=0, stride=1)\n",
    "        self.conv2_drop = nn.Dropout2d(0.1)\n",
    "        self.fc1 = nn.Linear(in_features=1024, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=10)\n",
    "        # self.bnm = nn.BatchNorm2d(64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # conv --> norm --> activation --> dropout --> pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = self.conv2_drop(F.relu(self.conv2(x))) \n",
    "        x = F.max_pool2d(x, 2)  \n",
    "        x = x.reshape(-1, 1024)\n",
    "        x = F.dropout(F.relu(self.fc1(x)), training=self.training, p=0.2)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3 , self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=0, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=0, stride=1)\n",
    "        self.conv2_drop = nn.Dropout2d(0.1)\n",
    "        self.fc1 = nn.Linear(in_features=1024, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=10)\n",
    "        # self.bnm = nn.BatchNorm2d(64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # conv --> norm --> activation --> dropout --> pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = self.conv2_drop(F.relu(self.conv2(x))) \n",
    "        x = F.max_pool2d(x, 2)  \n",
    "        x = x.reshape(-1, 1024)\n",
    "        x = F.dropout(F.relu(self.fc1(x)), training=self.training, p=0.2)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class CNN4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4 , self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, padding=2, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=5, padding=2, stride=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, padding=2, stride=1)\n",
    "        self.conv2_drop = nn.Dropout2d(0.1)\n",
    "        self.fc1 = nn.Linear(in_features=512, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
    "        # self.bnm = nn.BatchNorm2d(64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # conv --> norm --> activation --> dropout --> pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.relu(self.conv2(x)) \n",
    "        x = F.max_pool2d(x, 2)  \n",
    "        x = self.conv2_drop(F.relu(self.conv3(x))) \n",
    "        x = F.max_pool2d(x, 2)  \n",
    "        x = x.reshape(-1, 512)\n",
    "        x = F.dropout(F.relu(self.fc1(x)), training=self.training, p=0.2)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN4(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2_drop): Dropout2d(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = CNN4() # 1 and 3 are big but you get diminishing return after some point. Actually data augmentation would help\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = CNN2() # 1 and 3 are big but you get diminishing return after some point. Actually data augmentation would help\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "e471e447a9618edc7310bb15941054c30ea235a4"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, test_loader, EPOCHS=5, log_at_batch=False):\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Send to cpu or gpu \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Zero out the grads \n",
    "            optimizer.zero_grad()\n",
    "            # Get output\n",
    "            output = model(data)\n",
    "            # Get training loss\n",
    "            loss = criterion(output, target)\n",
    "            # BAckprop\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == target).sum()\n",
    "            #print(correct)\n",
    "            if batch_idx % 100 == 0 and log_at_batch:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(data), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
    "            \n",
    "        total_loss.append(loss.data)\n",
    "        total_acc.append(correct/len(train_loader.dataset))\n",
    "        print(\"Epoch {}\".format(epoch))\n",
    "        evaluate(model, test_loader)\n",
    "    \n",
    "    return {\"loss\": total_loss, \"accuracy\": total_acc} \n",
    "        \n",
    "def evaluate(network, test_loader):\n",
    "    correct = 0 \n",
    "    network.eval()\n",
    "    test_preds = torch.LongTensor()\n",
    "    target_cpu = torch.LongTensor()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = network(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            test_preds = torch.cat((test_preds, pred.cpu()), dim=0)\n",
    "            target_cpu = torch.cat((target_cpu, target.cpu()), dim=0)\n",
    "        print(\"Test accuracy:{:.3f}% \".format( float(correct) / (len(test_loader)*BATCH_SIZE)))\n",
    "    return test_preds, target_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters())# Default lr=0.001, betas=(0.9,0.999))\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "766f99fea9d2295443131e64e9bda28e1ea1efe5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Test accuracy:0.973% \n",
      "Epoch 1\n",
      "Test accuracy:0.976% \n",
      "Epoch 2\n",
      "Test accuracy:0.977% \n",
      "Epoch 3\n",
      "Test accuracy:0.983% \n",
      "Epoch 4\n",
      "Test accuracy:0.977% \n",
      "Epoch 5\n",
      "Test accuracy:0.986% \n",
      "Epoch 6\n",
      "Test accuracy:0.983% \n",
      "Epoch 7\n",
      "Test accuracy:0.984% \n",
      "Epoch 8\n",
      "Test accuracy:0.986% \n",
      "Epoch 9\n",
      "Test accuracy:0.986% \n",
      "Epoch 10\n",
      "Test accuracy:0.986% \n",
      "Epoch 11\n",
      "Test accuracy:0.985% \n",
      "Epoch 12\n",
      "Test accuracy:0.984% \n",
      "Epoch 13\n",
      "Test accuracy:0.986% \n",
      "Epoch 14\n",
      "Test accuracy:0.984% \n",
      "Epoch 15\n",
      "Test accuracy:0.987% \n",
      "Epoch 16\n",
      "Test accuracy:0.983% \n",
      "Epoch 17\n",
      "Test accuracy:0.989% \n",
      "Epoch 18\n",
      "Test accuracy:0.986% \n",
      "Epoch 19\n",
      "Test accuracy:0.984% \n"
     ]
    }
   ],
   "source": [
    "report = train(net, train_loader, criterion, optimizer, val_loader, EPOCHS=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Test accuracy:0.986% \n",
      "Epoch 1\n",
      "Test accuracy:0.988% \n",
      "Epoch 2\n",
      "Test accuracy:0.985% \n",
      "Epoch 3\n",
      "Test accuracy:0.988% \n",
      "Epoch 4\n",
      "Test accuracy:0.985% \n",
      "Epoch 5\n",
      "Test accuracy:0.987% \n",
      "Epoch 6\n",
      "Test accuracy:0.984% \n",
      "Epoch 7\n",
      "Test accuracy:0.987% \n",
      "Epoch 8\n",
      "Test accuracy:0.984% \n",
      "Epoch 9\n",
      "Test accuracy:0.986% \n"
     ]
    }
   ],
   "source": [
    "report2 = train(net, train_loader, criterion, optimizer, val_loader, EPOCHS=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(network, test_loader):\n",
    "    correct = 0 \n",
    "    network.eval()\n",
    "    test_preds = torch.LongTensor()\n",
    "    target_cpu = torch.LongTensor()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            output = network(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            test_preds = torch.cat((test_preds, pred.cpu()), dim=0)\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "3703af54a320fd81bfa426be17655a3cebec5ac4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test_preds, _ = evaluate(net, test_loader)\n",
    "test_preds = get_results(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "submission_df['Label'] = test_preds.numpy().squeeze()\n",
    "submission_df.to_csv(path_or_buf='submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
